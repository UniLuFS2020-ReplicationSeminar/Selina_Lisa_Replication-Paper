---
title: "Replication Report"
author:
- affiliation: University of Lucerne
  email: selina.nguyen@stud.unilu.ch
  name: Selina Nguyen
- affiliation: University of Lucerne
  email: lisa.thai@stud.unilu.ch
  name: Lisa Thai
date: "6/3/2020"
output:
  word_document:
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
subtitle: The ideological nationalization of partisan subconstituencies in the American
  States (2018) by Devin Caughey · James Dunham · Christopher Warshaw
---
word count: 1975

# Introduction 
The paper "The ideological nationalization of partisan subconstituencies in the American States" (2018) by Caughey et al. enables to question and to re-consider previous knwoledge about the ideological polarization among the Congress members and the among the population. Before, there was a consensus that the accelarating and increasing polarization between Democrats and Republicans prevails among Congress members. Mass polarization among citizens were not measureable and therefore considered to be low and rather stable. Caughey et al. made a great contribution by showing that polarization among citizens existists and is increasing too. This was possible by using estimated scores about the ideological position of the average Democrats and Republicans using survey-data that covers attitudes about economic, racial, and social policy aggregated for each state.


# Transparency & Replicability: 
The fact, that the authors provided the scripts and datasets of the paper on [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/RHFPVV) was very helpful and a good starting point for the replication work. However, it is important to note that if someone would try to replicate or reproduce the whole paper from scratch – which means by checking the operationalization of the survey questions or the classification of roll-call voting data into the three domains of economic, social, racial issues – that would not be possible based on the material that the authors have provided on Harvard Dataverse. The latter had been conducted by another research project called “Policy Agendas Project” by other authors (Adler and Wilkerson 2017), which Caughey et al. have adopted in their paper. Thus, Caughey et al. have been very transparent on which previous work they have built on and which surveys have been used. Therefore, it might also be possible to reproduce the whole paper from scratch, if someone wishes. In the paper, the authors justified and reflected their decisions transparently and even provide additional useful information in the footnotes – for example, which R packages they have used for certain calculations. However, in the officially published version that we downloaded from [Springer](https://link.springer.com/article/10.1007/s11127-018-0543-3), there was no appendix provided in comparison to a pre-print version that we have accidentally found through google scholar. The supplementary appendix is 5 pages long and contains a detailed explanation of how the IRT model works. For sure, this has helped to get a better understanding of the model. Especially, if someone wishes to experiment more with this model or make some modifications, the appendix would be very useful. However, for us, the method and the model remained quite complex and not easy to fully understand. Therefore, it was very hard to think of ways on how we could have questioned or even improved the decisions that the authors have made. And since we are both beginners that just started got started to work with R, we also had to invest a lot of time in just making the codes run. 

The codes for the first figure “Senate ideal Points” of figure 1 on page 138 were written in base R and we had troubles running them on our computers. Therefore, we decided to transform the codes that were not running into tidyverse codes. Even though some comments on the codes were provided, it was not always self-explanatory what the codes did or why they were used. But by jumping forth and back to the original paper, and some guessing, it became understandable and comprehensive what the authors have done. Thus, we would say that what the authors have described in the paper matches the content of the script. However, the dataset that we generated with the data and the script provided by the authors contains seven variables. The variable names that were chosen by the authors were confusing for us because they are very similar, for example: “dynamic_ideal” and “dynamic_ideal_norm”. Furthermore, for those metric values, it is hard or almost impossible to trace back on how exactly they were generated and calculated in the first place. It seems that the authors had done that in a different script that was not published on Harvard Dataverse. This was a bit surprising for us because we had assumed that this would be visible and possible to trace back in the provided script. Hence, we had no other choice than just to rely upon and work with the metric values provided by the authors. 


# Replication Work
In this following section we will describe our replication process, as well as explain the code we used to create the figure depicting the senate ideal points.

## Intial Setup
We started by downloading and selecting the necessary packages, such as dplyr and ggplot2. Differently from the original syntax, we left out the data.table, haven and readr package.
```{r setup, results='hide', message=FALSE, warning=FALSE}
# Download packages
library(tidyverse)
library(dplyr)
library(ggplot2)
library(data.table)
```

After setting the working directory, following the original syntax, we loaded three datasets into R, while also renaming them according to the issue domains _Economic_, _Social_ and _Racial_. This resulted also into an unnecessary dataframe called _table_, which we removed for clarity's sake.
```{r load data, results='hide'}
# Set working directory
here::here()

# Load and rename datasets according to issue domains
Economic <- get(load(here::here("Data","senate-econ.RData")))
Social <- get(load(here::here("Data","senate-social.RData")))
Racial <- get(load(here::here("Data","senate-race.RData")))
remove(table)
```

Then, we proceeded to merge the datasets into a single one, which we named _ideals_. As we still wanted to be able to identify from which issue domain the values came from, we added a column called _domain_.
```{r merge data, results='hide'}
# Merge datasets into one, but specify which domain the values belong to
ideals <- bind_rows(list(Economic = Economic, Social = Social, Racial = Racial), .id = "domain")
```


## Optimizing the Dataset
After the initial setup, we continued by optimizing our dataset _ideals_ to create the graph, starting with filtering out roll call data in the racial and social domains that preceeded the 85th Congress. For all issue domains, including the economic one, we filtered out values that went beyond the 113th Congress.
The reason behind this specific filtering lies in the paper: "For the economic domain, we estimate senators’ ideal points in each congressional term between the 81th (1949–1950) and 113th (2013–2013). Because few roll call on social and race issues were voted on until the late 1950s, our estimates for these domains start in the 85th Congress (1957–1958)" (Caughey et al. 2018, 137).
Without thoroughly reading and comprehending the paper, we would not have figured out this essential step in the original syntax as it was not commented on.
```{r filter data, results='hide'}
# Filter out data after 113th Congress in all domains
# Filter out data before 85th Congress in racial and social domains 
ideals <- filter(ideals, congress <= 113,
                 !(domain == "Racial" & congress < 85),
                 !(domain == "Social" & congress < 85))
```

Next, we standardized the scores of the ideal points and named the new variable _dynamic_ideal_norm_. Here, not only did the authors describe the code, the normalization also matched what was described in the paper. The estimates of the ideal points were to be coded as to produce a mean of 0 and variance of 1 across senator-congresses (Caughey et al. 2018, 137).
To make sure we were on the right track, we tested our z-standardization by taking the mean and the standard deviation of the ideal points.
```{r normalization, results='hide'}
# Normalize the scores
ideals <- ideals %>% 
  group_by(domain) %>% 
  mutate(dynamic_ideal_norm = (dynamic_ideal - mean(dynamic_ideal, na.rm = T)) / sd(dynamic_ideal, na.rm = T))

# Check standardization
mean(ideals$dynamic_ideal_norm) # ~0
sd(ideals$dynamic_ideal_norm) # 1
```

Indicated by a comment in the original syntax, though, not in the paper, there are also presidential senators, who are identified with the state abbreviation _USA_, included in the roll call data. Thus, we also filtered them out. 
```{r filtering out presidents, results='hide'}
# Drop presidents
ideals <- filter(ideals, !(state_abbrev == "USA"))
```


## Creating the Graphs
After having reworked the dataframe, the Caughey et al. produce a first graph. However, as they comment in the syntax, this is not the final output, but to check the polarity.

From the original code, we had to deduce several steps First, they took the mean from the standardized ideal points and called the new variable _mean_ideal_. Then, they encoded the vector variable _party_code_ as a factor, presumably since the party code is a categorical variable and, therefore, has no numerical value.

It is explained neither in the paper, nor in the original syntax, that the dataset includes not only Republicans and Democrats, but also Conservatives and Independents. As the paper only focuses on polarization between Republican and Democratic senators, the other party members will need to be filtered out. After consulting the voteview website and looking at our data, we were able to figure out that the party codes for Republicans and Democrats were 100 and 200, respectively, while Conservatives were identified by 212 and Independents by 328.

We plotted our graph accordingly and were able to see the polarization of the senator's ideal points based on the issue domains. However, it is not clear to us why Caughey et al. had to check for polarity if the final graph was supposed to show exactly the polarization in Congress anyway.
```{r check polarity and test graph, results='hide'}
# Create a variable that is the mean of the ideal points
party_means <- ideals %>%
  group_by(domain, party_code, congress) %>% 
  mutate(mean_ideal = mean(dynamic_ideal_norm))

# Change party code variable into a factor
#party_means <- party_means %>% 
#  mutate(party_code = factor(party_code))

# Plot to check for polarity
# Only include Democrats and Republicans (e.g. party codes 100 and 200)
p1 <- ggplot(subset(party_means, party_code %in% c(100, 200))) +
  geom_line(mapping = aes(x = congress, y = mean_ideal, color = party_code)) +
  facet_wrap(~ domain)
```

To create the actual final output, i.e. the graph depicting the senators' ideal points, Caughey et al. created two functions to further subset their data, as well as "calculate[d] the ideal-point differences between senators from the same state but different parties, and then [we] average[d] the domain-specifc differences within each term" (Caughey et al. 2018, 137). Because the first function serves to basically filter the data, we decided to instead go step by step, following, but rewriting the original code.

Accordingly, we started by filtering out the missing values, along with the Independents and Conservatives. Then, we eliminated the states that are represented by only one party, since the graph has to show the within-state differences, not across the states. Next, we took the within-state-party average, in case there is more than one senator who represents a state in a Congress. Without the comments in the syntax, we would not have understood or undertaken the subsetting in the first place, even though they could potentially distort the findings.
```{r filtering, results='hide'}
# Drop any NA states and NA ideal points
ideals <- filter(ideals, !is.na(get("state_abbrev")) & !is.na(get("dynamic_ideal")))

# Filter out the Conservatives and Independents
ideals <- filter(ideals, !(party_code == 212), !(party_code == 328))

# Filter out the states that are represented by senators of only one party
ideals <- ideals %>% 
  group_by(congress, state_abbrev) %>% 
  mutate(two_party = length(unique(party_code)) > 1)

# Keep the states represented by both parties
ideals <- ideals %>% 
  filter(!(two_party == F))

# Take the within-state-party average, for the case in which there's more than one senator/member in a state-congress pair.    
ideals <- ideals %>% 
  group_by(congress, state_abbrev, party_code) %>% 
  mutate(dynamic_ideal_norm = mean(dynamic_ideal_norm))

# Take the within-state differences between parties in each congress
mean_state_diff <- function(ideal_points, time_var = "congress") {
  ideals = copy(ideal_points)
  setDT(ideals, key = c("congress", "state_abbrev", "party_code"))
  diffs <- ideals %>% 
    group_by(congress, state_abbrev) %>% 
    mutate(party_code = first(party_code),
           diff_score = dynamic_ideal[1] - dynamic_ideal[2], n = .N)
  mean_diffs <- diffs %>% 
    group_by(congress) %>% 
    mutate(mean_diff_score = mean(diff_score, na.rm = T), n = .N)
  mean_diffs
}
    

mean_diff_by_domain = function(ideals) {
  .ideals = copy(ideals)
  econ_diff <- mean_state_diff(filter(.ideals, domain == "Economic"))
  race_diff <- mean_state_diff(filter(.ideals, domain == "Racial"))
  social_diff <- mean_state_diff(filter(.ideals, domain == "Social"))
  
  diffs = rbindlist(list("Economic" = econ_diff,
                         "Racial" = race_diff,
                         "Social" = social_diff),
                    idcol = "Domain", fill = T)
  
  congresses <- readRDS(here::here("Data", "congresses.Rds"))
  merge(diffs, congresses, by.x = "congress", by.y = "cong", all.x = T, all.y = F)
}

mean_diffs <- mean_diff_by_domain(ideals)


# Flip for same polarity as previous estimates
mean_diffs <- mean_diffs %>% 
  mutate(mean_diff_score = mean_diff_score * -1)
```

Finally, matching the procedure explained in the paper, we took the within-state differences between parties in each congress and plotted the graph.
```{r final graph, fig.height=4, fig.width=8, fig.cap="\\label{fig:figs}Figure 1: Our replicated graph of the senate ideal points."}
# Plot the graph
p2 <- ggplot(data = mean_diffs) +
  geom_line(mapping = aes(end_year, mean_diff_score, color = Domain, linetype = Domain)) +
  scale_linetype_manual(values=c("solid", "dashed", "dotdash")) +
  scale_y_continuous("Avg. Difference") +
  scale_x_continuous("Year", limits = c(1945, 2017), breaks = seq(1950, 2010, 10)) +
  ggtitle("Senate Ideal Points") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

p2
```

![Senate Ideal points](/Users/nhatnguyen/Desktop/Uni/FS20/MA Replication/LisaSelina_Replication/Selina_Lisa_Replication-Paper/Figs/Figure1_Senate_Ideal_Points.png) Figure 2: The original graph of the senate ideal points.

If we compare the replicated with the original graph, there are some noticeable differences. Most prominently, our graph shows average differences of above even 3, while in the original graph differences in senate ideal points barely go over 2, peaking after the year 2000. Perhaps our standardization of the scores did not result in the same normalized ideal points as it did in the original graph. The divergences from the original graph, such as some strong dips in the Economic domain line before 1980 and in all issue domain lines after 1990. most probably also stem from us having to rewrite almost all of the code, since the base R syntax, more often than not, was not recognized by our softwares.

However, despite our higher average differences, the overall trend indicated by our graph follows that of the original one. We can observe an upward polarization due to the increase of the average differences in senate ideal point estimates in all three issue domains. Especially, it seems senators within the same state disagree on economic topics the most, which Caughey et al. note in their paper as well. According to the authors, their main findings about the senate ideal points are consistent with prior studies and, therefore, ours seem to fit as well (Caughey et al. 2018, 137).


# Conclusion
While the transparency of the study, provided through methodological explanations in the paper and comments in the syntax, as well as replication data, code and figures made available online, seems relatively high, we definitely had to do our own research, namely on the roll call data from voteview. Thorough reading of the paper itself was essential to comprehend the coding, as was analyzing the dataset to understand the filtering steps. Though the comments were helpful, it would not have hurt for the authors to have given more information on the coding procedure. We could not determine whether the differences between our graph from the original one are due to coding mistakes we made while rewriting most of it, or due to errors in the syntax provided by the authors. However, the replication of the overall findings Caughey et al. made was only possible, because we were able to follow the theory and methodology in the paper and comprehend its translation into R code in the syntax. Through this exercise, we realized how important it is to thoroughly and tidily document one's process to ensure the possibility of reproduction and replication.

# Bibliography
* Caughey, Devin; James Dunham, Christopher Warshaw (2018): The ideological nationalization of partisan subconstituencies in the American States. Public Choice (176):133-151.Adler, E. S., & Wilkerson, J. (2017).
* Congressional bills project. National Science Foundation grants 880066 and 880061. <http://www.congressionalbills.org/download.html>.


